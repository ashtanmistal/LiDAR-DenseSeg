{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification of Data: PointNet++\n",
    "\n",
    "The first step in this process is to classify all unclassified data in the LiDAR dataset. This will ensure proper building skeletons prior to densification. \n",
    "\n",
    "We will be training a PointNet++ model to do this; The data will be trained on the already classified data. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "875a3c2cc5946ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unclassified\n",
    "Ground\n",
    "Low Vegetation\n",
    "Medium Vegetation\n",
    "High Vegetation\n",
    "Building\n",
    "Low Point (Noise)\n",
    "Reserved\n",
    "Water\n",
    "Rail\n",
    "Road Surface\n",
    "Reserved\n",
    "Wire - Guard (Shield)\n",
    "Wire - Conductor (Phase)\n",
    "Transmission Tower\n",
    "Wire-Structure Connector (Insulator)\n",
    " Bridge Deck\n",
    "High Noise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "692dbf025104b6c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "246ae414aa05220b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:31<00:00, 31.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# training python script is in pointnetpp/train_semseg.py\n",
    "# we need to find hyperparameters for the model\n",
    "# random search for hyperparameters\n",
    "\n",
    "\"\"\"\n",
    "AVALABLE HYPERPARAMETERS:\n",
    "--batch_size', type=int, default=1, help='Batch Size during training [default: 16]')\n",
    "--epoch', default=64, type=int, help='Epoch to run [default: 32]')\n",
    "--learning_rate', default=1e-3, type=float, help='Initial learning rate [default: 0.001]')\n",
    "--gpu', type=str, default='0', help='GPU to use [default: GPU 0]')\n",
    "--optimizer', type=str, default='Adam', help='Adam or SGD [default: Adam]')\n",
    "--log_dir', type=str, default=None, help='Log path [default: None]')\n",
    "--decay_rate', type=float, default=0.001, help='weight decay [default: 1e-4]')\n",
    "--npoint', type=int, default=4096, help='Point Number [default: 4096]')\n",
    "--step_size', type=int, default=10, help='Decay step for lr decay [default: every 10 epochs]')\n",
    "--lr_decay', type=float, default=0.7, help='Decay rate for lr decay [default: 0.7]')\n",
    "\"\"\"\n",
    "\n",
    "# The ones we will be changing are:\n",
    "# batch_size (between 1 and 32)\n",
    "# learning_rate (between 1e-5 and 1e-1), choose on log scale\n",
    "# optimizer (Adam or SGD)\n",
    "# decay_rate (between 1e-5 and 1e-1), choose on log scale\n",
    "# npoint (between 256 and 16384), choose on log scale\n",
    "# step_size (between 1 and 10)\n",
    "# lr_decay (between 0.5 and 0.9)\n",
    "from random import randint, uniform\n",
    "import os\n",
    "import tqdm\n",
    "import subprocess\n",
    "\n",
    "def random_hyperparameters():\n",
    "    batch_size = randint(1, 32)\n",
    "    learning_rate = 10 ** uniform(-5, -1)\n",
    "    optimizer = \"Adam\" if randint(0, 1) == 0 else \"SGD\"\n",
    "    decay_rate = 10 ** uniform(-5, -1)\n",
    "    npoint = 2 ** randint(8, 14)\n",
    "    step_size = randint(1, 10)\n",
    "    lr_decay = uniform(0.5, 0.9)\n",
    "    return batch_size, learning_rate, optimizer, decay_rate, npoint, step_size, lr_decay\n",
    "log_dir = \"random_search\"\n",
    "num_trials = 1000\n",
    "results = []\n",
    "for i in tqdm.tqdm(range(num_trials)):\n",
    "    batch_size, learning_rate, optimizer, decay_rate, npoint, step_size, lr_decay = random_hyperparameters()\n",
    "    # print(\"batch_size: {}, learning_rate: {}, optimizer: {}, decay_rate: {}, npoint: {}, step_size: {}, lr_decay: {}\".format(batch_size, learning_rate, optimizer, decay_rate, npoint, step_size, lr_decay))\n",
    "    wq = \"python train_semseg.py --batch_size {} --learning_rate {} --optimizer {} --decay_rate {} --npoint {} --step_size {} --lr_decay {} --log_dir {}\".format(batch_size, learning_rate, optimizer, decay_rate, npoint, step_size, lr_decay, log_dir)\n",
    "    # run and wait for process to finish\n",
    "    result = subprocess.run(wq, shell=True, capture_output=True, text=True)\n",
    "    results.append(result.stdout)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T06:35:53.058081Z",
     "start_time": "2023-12-12T06:35:21.207747600Z"
    }
   },
   "id": "bc2777d1e7e8bb9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3b0463f1298adc45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
